{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2t=pd.read_csv('Face2Text.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4076"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2t.filename.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2t['description']=f2t['description'].str.replace(\"[^a-zA-Z]\",\" \")\n",
    "f2t['description']=f2t['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(f2t['description'])):\n",
    "    f2t['description'][i]='seqstart '+f2t['description'][i]+' seqend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv('vocab.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtoin={}\n",
    "intoword={}\n",
    "ind=0\n",
    "for i in vocab[0]:\n",
    "    wordtoin[i]=ind\n",
    "    intoword[ind]=i\n",
    "    ind+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whch': 0,\n",
       " 'th': 1,\n",
       " 'loosely': 2,\n",
       " 'shaggy': 3,\n",
       " 'deep': 4,\n",
       " 'shaped': 5,\n",
       " 'naturally': 6,\n",
       " 'it': 7,\n",
       " 'aged': 8,\n",
       " 'emphasising': 9,\n",
       " 'had': 10,\n",
       " 'pinned': 11,\n",
       " 'imitating': 12,\n",
       " 'stubbly': 13,\n",
       " 'unable': 14,\n",
       " 'frame': 15,\n",
       " 'mouthed': 16,\n",
       " 'decay': 17,\n",
       " 'blank': 18,\n",
       " 'surprise': 19,\n",
       " 'between': 20,\n",
       " 'plaid': 21,\n",
       " 'match': 22,\n",
       " 'styled': 23,\n",
       " 'highlighted': 24,\n",
       " 'enck': 25,\n",
       " 'reddish': 26,\n",
       " 'kinky': 27,\n",
       " 'acting': 28,\n",
       " 'small': 29,\n",
       " 'suntanned': 30,\n",
       " 'distance': 31,\n",
       " 'built': 32,\n",
       " 'bony': 33,\n",
       " 'type': 34,\n",
       " 'pastel': 35,\n",
       " 'combed': 36,\n",
       " 'oink': 37,\n",
       " 'stud': 38,\n",
       " 'tint': 39,\n",
       " 'ibig': 40,\n",
       " 'teetj': 41,\n",
       " 'amek': 42,\n",
       " 'round': 43,\n",
       " 'ann': 44,\n",
       " 'eyerbows': 45,\n",
       " 'believe': 46,\n",
       " 'narrow': 47,\n",
       " 'wearling': 48,\n",
       " 'matching': 49,\n",
       " 'french': 50,\n",
       " 'blusher': 51,\n",
       " 'mediterranean': 52,\n",
       " 'awe': 53,\n",
       " 'top': 54,\n",
       " 'believing': 55,\n",
       " 'upstyle': 56,\n",
       " 'seeon': 57,\n",
       " 'cover': 58,\n",
       " 'wrinkly': 59,\n",
       " 'am': 60,\n",
       " 'veiny': 61,\n",
       " 'straw': 62,\n",
       " 'under': 63,\n",
       " 'toothbrush': 64,\n",
       " 'dense': 65,\n",
       " 'tattoos': 66,\n",
       " 'otherwise': 67,\n",
       " 'cry': 68,\n",
       " 'do': 69,\n",
       " 'rasta': 70,\n",
       " 'cannot': 71,\n",
       " 'pencil': 72,\n",
       " 'time': 73,\n",
       " 'my': 74,\n",
       " 'weak': 75,\n",
       " 'mutton': 76,\n",
       " 'haired': 77,\n",
       " 's': 78,\n",
       " 'including': 79,\n",
       " 'holding': 80,\n",
       " 'pointy': 81,\n",
       " 'bearded': 82,\n",
       " 'gentle': 83,\n",
       " 'math': 84,\n",
       " 'grimace': 85,\n",
       " 'goes': 86,\n",
       " 'right': 87,\n",
       " 'soul': 88,\n",
       " 'wearing': 89,\n",
       " 'hooded': 90,\n",
       " 'gold': 91,\n",
       " 'earlobes': 92,\n",
       " 'chinstrap': 93,\n",
       " 'smilng': 94,\n",
       " 'patch': 95,\n",
       " 'barbie': 96,\n",
       " 'loko': 97,\n",
       " 'make': 98,\n",
       " 'knot': 99,\n",
       " 'side': 100,\n",
       " 'tightly': 101,\n",
       " 'ribbon': 102,\n",
       " 'happily': 103,\n",
       " 'wispy': 104,\n",
       " 'ash': 105,\n",
       " 'happened': 106,\n",
       " 'sminned': 107,\n",
       " 'changes': 108,\n",
       " 'mousache': 109,\n",
       " 'dread': 110,\n",
       " 'jas': 111,\n",
       " 'thinning': 112,\n",
       " 'ha': 113,\n",
       " 'covering': 114,\n",
       " 'veil': 115,\n",
       " 'older': 116,\n",
       " 'upturned': 117,\n",
       " 'prescription': 118,\n",
       " 'blondish': 119,\n",
       " 'hues': 120,\n",
       " 'metal': 121,\n",
       " 'burns': 122,\n",
       " 'gaunt': 123,\n",
       " 'stretched': 124,\n",
       " 'jawine': 125,\n",
       " 'egaed': 126,\n",
       " 'smirking': 127,\n",
       " 'one': 128,\n",
       " 'filipino': 129,\n",
       " 'yuong': 130,\n",
       " 'tilted': 131,\n",
       " 'cap': 132,\n",
       " 'form': 133,\n",
       " 'fringe': 134,\n",
       " 'two': 135,\n",
       " 'striped': 136,\n",
       " 'e': 137,\n",
       " 'bald': 138,\n",
       " 'pattern': 139,\n",
       " 'mud': 140,\n",
       " 'adam': 141,\n",
       " 'bike': 142,\n",
       " 'crystal': 143,\n",
       " 'their': 144,\n",
       " 'struggling': 145,\n",
       " 'choker': 146,\n",
       " 'maskara': 147,\n",
       " 'coloured': 148,\n",
       " 'modern': 149,\n",
       " 'chocolate': 150,\n",
       " 'hand': 151,\n",
       " 'exposing': 152,\n",
       " 'angular': 153,\n",
       " 'so': 154,\n",
       " 'jacket': 155,\n",
       " 'bucket': 156,\n",
       " 'forced': 157,\n",
       " 'rabbit': 158,\n",
       " 'atop': 159,\n",
       " 'hawk': 160,\n",
       " 'larhe': 161,\n",
       " 'starting': 162,\n",
       " 'fascinator': 163,\n",
       " 'leathery': 164,\n",
       " 'feet': 165,\n",
       " 'fuzz': 166,\n",
       " 'shped': 167,\n",
       " 'jawline': 168,\n",
       " 'braces': 169,\n",
       " 'od': 170,\n",
       " 'exceptionally': 171,\n",
       " 'scowling': 172,\n",
       " 'glimpse': 173,\n",
       " 'water': 174,\n",
       " 'changing': 175,\n",
       " 'protruding': 176,\n",
       " 'shaven': 177,\n",
       " 'say': 178,\n",
       " 'been': 179,\n",
       " 'hands': 180,\n",
       " 'without': 181,\n",
       " 'along': 182,\n",
       " 'voluminous': 183,\n",
       " 'strands': 184,\n",
       " 'concealed': 185,\n",
       " 'shpwing': 186,\n",
       " 'accented': 187,\n",
       " 'that': 188,\n",
       " 'front': 189,\n",
       " 'causes': 190,\n",
       " 'too': 191,\n",
       " 'whether': 192,\n",
       " 'sunhat': 193,\n",
       " 'concealing': 194,\n",
       " 'except': 195,\n",
       " 'licking': 196,\n",
       " 'smokey': 197,\n",
       " 'heavily': 198,\n",
       " 'colored': 199,\n",
       " 'ponytail': 200,\n",
       " 'curtained': 201,\n",
       " 'at': 202,\n",
       " 'moment': 203,\n",
       " 'visible': 204,\n",
       " 'boywith': 205,\n",
       " 'receding': 206,\n",
       " 'bonnet': 207,\n",
       " 'unibrow': 208,\n",
       " 'by': 209,\n",
       " 'jewellery': 210,\n",
       " 'sharply': 211,\n",
       " 'crosseyed': 212,\n",
       " 'excited': 213,\n",
       " 'solemn': 214,\n",
       " 'teenage': 215,\n",
       " 'emphasises': 216,\n",
       " 'entire': 217,\n",
       " 'corners': 218,\n",
       " 'braided': 219,\n",
       " 'becoming': 220,\n",
       " 'area': 221,\n",
       " 'whitish': 222,\n",
       " 'narrowish': 223,\n",
       " 'teenager': 224,\n",
       " 'tips': 225,\n",
       " 'prominant': 226,\n",
       " 'hooked': 227,\n",
       " 'navy': 228,\n",
       " 'long': 229,\n",
       " 're': 230,\n",
       " 'whole': 231,\n",
       " 'skinned': 232,\n",
       " 'appears': 233,\n",
       " 'greasy': 234,\n",
       " 'sub': 235,\n",
       " 'look': 236,\n",
       " 'pouting': 237,\n",
       " 'tied': 238,\n",
       " 'tears': 239,\n",
       " 'although': 240,\n",
       " 'stained': 241,\n",
       " 'bob': 242,\n",
       " 'many': 243,\n",
       " 'sorrowful': 244,\n",
       " 'concerned': 245,\n",
       " 'dirt': 246,\n",
       " 'smoking': 247,\n",
       " 'state': 248,\n",
       " 'originally': 249,\n",
       " 'headset': 250,\n",
       " 'spectacles': 251,\n",
       " 'achieved': 252,\n",
       " 'asleep': 253,\n",
       " 'beneath': 254,\n",
       " 'arch': 255,\n",
       " 'ombr': 256,\n",
       " 'haircut': 257,\n",
       " 'flowers': 258,\n",
       " 'hat': 259,\n",
       " 'teal': 260,\n",
       " 'slicked': 261,\n",
       " 'unimpressed': 262,\n",
       " 'squared': 263,\n",
       " 'dark': 264,\n",
       " 'rounded': 265,\n",
       " 'colour': 266,\n",
       " 'blushing': 267,\n",
       " 'smilnig': 268,\n",
       " 'thinking': 269,\n",
       " 'lipsa': 270,\n",
       " 'cheekbones': 271,\n",
       " 'fedora': 272,\n",
       " 'whereas': 273,\n",
       " 'eyebrows': 274,\n",
       " 'reflective': 275,\n",
       " 'accentuates': 276,\n",
       " 'beret': 277,\n",
       " 'mouth': 278,\n",
       " 'boy': 279,\n",
       " 'suggest': 280,\n",
       " 'flattish': 281,\n",
       " 'slighly': 282,\n",
       " 'still': 283,\n",
       " 'hard': 284,\n",
       " 'set': 285,\n",
       " 'droopy': 286,\n",
       " 'ball': 287,\n",
       " 'sun': 288,\n",
       " 'for': 289,\n",
       " 'speech': 290,\n",
       " 'featured': 291,\n",
       " 'sideburns': 292,\n",
       " 'cut': 293,\n",
       " 'loudly': 294,\n",
       " 'yet': 295,\n",
       " 'square': 296,\n",
       " 'bronze': 297,\n",
       " 'extremely': 298,\n",
       " 'aroundd': 299,\n",
       " 'woman': 300,\n",
       " 'tipped': 301,\n",
       " 'copper': 302,\n",
       " 'across': 303,\n",
       " 'fading': 304,\n",
       " 'child': 305,\n",
       " 'faces': 306,\n",
       " 'circumference': 307,\n",
       " 'football': 308,\n",
       " 'annoyed': 309,\n",
       " 'seemingly': 310,\n",
       " 'bone': 311,\n",
       " 'undercut': 312,\n",
       " 'mostly': 313,\n",
       " 'some': 314,\n",
       " 'sre': 315,\n",
       " 'apart': 316,\n",
       " 'lines': 317,\n",
       " 'breathless': 318,\n",
       " 'hairband': 319,\n",
       " 'parts': 320,\n",
       " 'striaght': 321,\n",
       " 'slightly': 322,\n",
       " 'earrigns': 323,\n",
       " 'moustache': 324,\n",
       " 'seems': 325,\n",
       " 'comb': 326,\n",
       " 'beady': 327,\n",
       " 'aback': 328,\n",
       " 'elderly': 329,\n",
       " 'chiselled': 330,\n",
       " 'sunshine': 331,\n",
       " 'doubtful': 332,\n",
       " 'layered': 333,\n",
       " 'define': 334,\n",
       " 'pentagon': 335,\n",
       " 'half': 336,\n",
       " 'nearly': 337,\n",
       " 'indicating': 338,\n",
       " 'carefully': 339,\n",
       " 'afro': 340,\n",
       " 'tip': 341,\n",
       " 'thickly': 342,\n",
       " 'hairs': 343,\n",
       " 'hoops': 344,\n",
       " 'shining': 345,\n",
       " 'greenish': 346,\n",
       " 'plain': 347,\n",
       " 'are': 348,\n",
       " 'underneath': 349,\n",
       " 'glaring': 350,\n",
       " 'original': 351,\n",
       " 'destress': 352,\n",
       " 'golden': 353,\n",
       " 'made': 354,\n",
       " 'there': 355,\n",
       " 'intimidated': 356,\n",
       " 'lower': 357,\n",
       " 'gray': 358,\n",
       " 'earrings': 359,\n",
       " 'indifferent': 360,\n",
       " 'partly': 361,\n",
       " 'frameless': 362,\n",
       " 'were': 363,\n",
       " 'amazed': 364,\n",
       " 'thick': 365,\n",
       " 'grimacing': 366,\n",
       " 'them': 367,\n",
       " 'peach': 368,\n",
       " 'futuristic': 369,\n",
       " 'heavy': 370,\n",
       " 'because': 371,\n",
       " 'clack': 372,\n",
       " 'facw': 373,\n",
       " 'raising': 374,\n",
       " 'teen': 375,\n",
       " 'visiblr': 376,\n",
       " 'disgust': 377,\n",
       " 'left': 378,\n",
       " 'braids': 379,\n",
       " 'what': 380,\n",
       " 'pale': 381,\n",
       " 'due': 382,\n",
       " 'short': 383,\n",
       " 'pursed': 384,\n",
       " 'curls': 385,\n",
       " 'wih': 386,\n",
       " 'shirt': 387,\n",
       " 'bags': 388,\n",
       " 'from': 389,\n",
       " 'evident': 390,\n",
       " 'toothy': 391,\n",
       " 'fascinated': 392,\n",
       " 'satisfaction': 393,\n",
       " 'others': 394,\n",
       " 'hint': 395,\n",
       " 'resembling': 396,\n",
       " 'each': 397,\n",
       " 'end': 398,\n",
       " 'visivle': 399,\n",
       " 'highlighting': 400,\n",
       " 'continent': 401,\n",
       " 'hey': 402,\n",
       " 'curtly': 403,\n",
       " 'hazel': 404,\n",
       " 'gel': 405,\n",
       " 'clear': 406,\n",
       " 'brass': 407,\n",
       " 'crooked': 408,\n",
       " 'pierced': 409,\n",
       " 'thing': 410,\n",
       " 'roundish': 411,\n",
       " 'ad': 412,\n",
       " 'shee': 413,\n",
       " 'bakwards': 414,\n",
       " 'shoulder': 415,\n",
       " 'defined': 416,\n",
       " 'if': 417,\n",
       " 'female': 418,\n",
       " 'less': 419,\n",
       " 'blowing': 420,\n",
       " 'albeit': 421,\n",
       " 'falling': 422,\n",
       " 'smirk': 423,\n",
       " 'east': 424,\n",
       " 'freckles': 425,\n",
       " 'eyebows': 426,\n",
       " 'mascara': 427,\n",
       " 'sharp': 428,\n",
       " 'scraggly': 429,\n",
       " 'fades': 430,\n",
       " 'beaky': 431,\n",
       " 'pleased': 432,\n",
       " 'uncombed': 433,\n",
       " 'just': 434,\n",
       " 'part': 435,\n",
       " 'wirh': 436,\n",
       " 'and': 437,\n",
       " 'caught': 438,\n",
       " 'dot': 439,\n",
       " 'middle': 440,\n",
       " 'defining': 441,\n",
       " 'somewhatg': 442,\n",
       " 'come': 443,\n",
       " 'hood': 444,\n",
       " 'crossing': 445,\n",
       " 'flared': 446,\n",
       " 'large': 447,\n",
       " 'case': 448,\n",
       " 'near': 449,\n",
       " 'features': 450,\n",
       " 'eyelids': 451,\n",
       " 'especially': 452,\n",
       " 'though': 453,\n",
       " 'purple': 454,\n",
       " 'graying': 455,\n",
       " 'deepset': 456,\n",
       " 'blakc': 457,\n",
       " 'flowing': 458,\n",
       " 'shape': 459,\n",
       " 'sweat': 460,\n",
       " 'haor': 461,\n",
       " 'reaching': 462,\n",
       " 'straightened': 463,\n",
       " 'shut': 464,\n",
       " 'goggles': 465,\n",
       " 'qhich': 466,\n",
       " 'stand': 467,\n",
       " 'smmiling': 468,\n",
       " 'sports': 469,\n",
       " 'eye': 470,\n",
       " 'point': 471,\n",
       " 'trying': 472,\n",
       " 'rhair': 473,\n",
       " 'baseball': 474,\n",
       " 'awkward': 475,\n",
       " 'irritated': 476,\n",
       " 'winter': 477,\n",
       " 'male': 478,\n",
       " 'trimmed': 479,\n",
       " 'lot': 480,\n",
       " 'turned': 481,\n",
       " 'microphone': 482,\n",
       " 'protesting': 483,\n",
       " 'dangly': 484,\n",
       " 'british': 485,\n",
       " 'far': 486,\n",
       " 'wet': 487,\n",
       " 'got': 488,\n",
       " 'grows': 489,\n",
       " 'jawlinw': 490,\n",
       " 'traces': 491,\n",
       " 'standing': 492,\n",
       " 'light': 493,\n",
       " 'laughing': 494,\n",
       " 'lens': 495,\n",
       " 'mullet': 496,\n",
       " 'beach': 497,\n",
       " 'jewel': 498,\n",
       " 'drenched': 499,\n",
       " 'no': 500,\n",
       " 'greyish': 501,\n",
       " 'frizz': 502,\n",
       " 'brownish': 503,\n",
       " 'headphones': 504,\n",
       " 'oval': 505,\n",
       " 'lazy': 506,\n",
       " 'blown': 507,\n",
       " 'hairline': 508,\n",
       " 'while': 509,\n",
       " 'squinty': 510,\n",
       " 'shyly': 511,\n",
       " 'complimented': 512,\n",
       " 'action': 513,\n",
       " 'delicate': 514,\n",
       " 'other': 515,\n",
       " 'pleasantly': 516,\n",
       " 'muth': 517,\n",
       " 'paying': 518,\n",
       " 'swimming': 519,\n",
       " 'saying': 520,\n",
       " 'young': 521,\n",
       " 'wrinkled': 522,\n",
       " 'face': 523,\n",
       " 'porcelain': 524,\n",
       " 'patches': 525,\n",
       " 'hid': 526,\n",
       " 'ling': 527,\n",
       " 'someone': 528,\n",
       " 'eyebrow': 529,\n",
       " 'patchy': 530,\n",
       " 'parted': 531,\n",
       " 'than': 532,\n",
       " 'rectangular': 533,\n",
       " 'eyelashes': 534,\n",
       " 'sad': 535,\n",
       " 'old': 536,\n",
       " 'with': 537,\n",
       " 'idea': 538,\n",
       " 'greying': 539,\n",
       " 'frowning': 540,\n",
       " 'raised': 541,\n",
       " 'transparent': 542,\n",
       " 'matches': 543,\n",
       " 'cheeky': 544,\n",
       " 'heard': 545,\n",
       " 'relation': 546,\n",
       " 'contoured': 547,\n",
       " 'hidden': 548,\n",
       " 'besides': 549,\n",
       " 'rock': 550,\n",
       " 'eastern': 551,\n",
       " 'sliight': 552,\n",
       " 'beak': 553,\n",
       " 'dirty': 554,\n",
       " 'upon': 555,\n",
       " 'roman': 556,\n",
       " 'intense': 557,\n",
       " 'chops': 558,\n",
       " 'womann': 559,\n",
       " 'teeeth': 560,\n",
       " 'jawlinwe': 561,\n",
       " 'adidas': 562,\n",
       " 'double': 563,\n",
       " 'glam': 564,\n",
       " 'chin': 565,\n",
       " 'sings': 566,\n",
       " 'unease': 567,\n",
       " 'fashioned': 568,\n",
       " 'very': 569,\n",
       " 'man': 570,\n",
       " 'angry': 571,\n",
       " 'shade': 572,\n",
       " 'accompanying': 573,\n",
       " 'beards': 574,\n",
       " 'headscarf': 575,\n",
       " 'formed': 576,\n",
       " 'plastic': 577,\n",
       " 'ahor': 578,\n",
       " 'shortish': 579,\n",
       " 'aquiline': 580,\n",
       " 'gloss': 581,\n",
       " 'baring': 582,\n",
       " 'hie': 583,\n",
       " 'any': 584,\n",
       " 'mo': 585,\n",
       " 'photo': 586,\n",
       " 'way': 587,\n",
       " 'not': 588,\n",
       " 'genuine': 589,\n",
       " 'teardrops': 590,\n",
       " 'paint': 591,\n",
       " 'straight': 592,\n",
       " 'tennis': 593,\n",
       " 'beading': 594,\n",
       " 'girl': 595,\n",
       " 'fac': 596,\n",
       " 'ring': 597,\n",
       " 'earringas': 598,\n",
       " 'wool': 599,\n",
       " 'beige': 600,\n",
       " 'pallid': 601,\n",
       " 'happu': 602,\n",
       " 'despite': 603,\n",
       " 'shouting': 604,\n",
       " 'expressive': 605,\n",
       " 'finger': 606,\n",
       " 'aronud': 607,\n",
       " 'comprehend': 608,\n",
       " 'amused': 609,\n",
       " 'lock': 610,\n",
       " 'retro': 611,\n",
       " 'largish': 612,\n",
       " 'into': 613,\n",
       " 'resting': 614,\n",
       " 'backed': 615,\n",
       " 'cigar': 616,\n",
       " 'marks': 617,\n",
       " 'tones': 618,\n",
       " 'black': 619,\n",
       " 'pressed': 620,\n",
       " 'hs': 621,\n",
       " 'angled': 622,\n",
       " 'amber': 623,\n",
       " 'bindi': 624,\n",
       " 'army': 625,\n",
       " 'worried': 626,\n",
       " 'think': 627,\n",
       " 'layers': 628,\n",
       " 'log': 629,\n",
       " 'beauty': 630,\n",
       " 'bow': 631,\n",
       " 'sight': 632,\n",
       " 'couple': 633,\n",
       " 'rollers': 634,\n",
       " 'fed': 635,\n",
       " 'nike': 636,\n",
       " 'neat': 637,\n",
       " 'whiich': 638,\n",
       " 'neutral': 639,\n",
       " 'pursing': 640,\n",
       " 'tanned': 641,\n",
       " 'hies': 642,\n",
       " 'dreadlocks': 643,\n",
       " 'winking': 644,\n",
       " 'balding': 645,\n",
       " 'tall': 646,\n",
       " 'puffing': 647,\n",
       " 'roubd': 648,\n",
       " 't': 649,\n",
       " 'rimmed': 650,\n",
       " 'rlips': 651,\n",
       " 'pigtails': 652,\n",
       " 'mark': 653,\n",
       " 'o': 654,\n",
       " 'shoulders': 655,\n",
       " 'shy': 656,\n",
       " 'place': 657,\n",
       " 'bones': 658,\n",
       " 'off': 659,\n",
       " 'facwe': 660,\n",
       " 'radiant': 661,\n",
       " 'somewhat': 662,\n",
       " 'difficult': 663,\n",
       " 'squarish': 664,\n",
       " 'shocked': 665,\n",
       " 'ginger': 666,\n",
       " 'button': 667,\n",
       " 'mustache': 668,\n",
       " 'scary': 669,\n",
       " 'soft': 670,\n",
       " 'gently': 671,\n",
       " 'admiring': 672,\n",
       " 'tiny': 673,\n",
       " 'spiked': 674,\n",
       " 'plump': 675,\n",
       " 'haas': 676,\n",
       " 'peace': 677,\n",
       " 'wide': 678,\n",
       " 'pigmentation': 679,\n",
       " 'open': 680,\n",
       " 'dusting': 681,\n",
       " 'parting': 682,\n",
       " 'cherry': 683,\n",
       " 'frizzy': 684,\n",
       " 'outward': 685,\n",
       " 'revealing': 686,\n",
       " 'ver': 687,\n",
       " 'instrument': 688,\n",
       " 'spiky': 689,\n",
       " 'hints': 690,\n",
       " 'makeup': 691,\n",
       " 'dimples': 692,\n",
       " 'smile': 693,\n",
       " 'brought': 694,\n",
       " 'surrounded': 695,\n",
       " 'high': 696,\n",
       " 'tan': 697,\n",
       " 'but': 698,\n",
       " 'dressed': 699,\n",
       " 'happy': 700,\n",
       " 'understand': 701,\n",
       " 'tidy': 702,\n",
       " 'playing': 703,\n",
       " 'banana': 704,\n",
       " 'f': 705,\n",
       " 'dreaming': 706,\n",
       " 'goatie': 707,\n",
       " 'perfect': 708,\n",
       " 'age': 709,\n",
       " 'tense': 710,\n",
       " 'taken': 711,\n",
       " 'beard': 712,\n",
       " 'dyed': 713,\n",
       " 'of': 714,\n",
       " 'colouted': 715,\n",
       " 'lipped': 716,\n",
       " 'thought': 717,\n",
       " 'see': 718,\n",
       " 'military': 719,\n",
       " 'squints': 720,\n",
       " 'letting': 721,\n",
       " 'is': 722,\n",
       " 'dive': 723,\n",
       " 'puffed': 724,\n",
       " 'swollen': 725,\n",
       " 'comber': 726,\n",
       " 'show': 727,\n",
       " 'watching': 728,\n",
       " 'separated': 729,\n",
       " 'blonde': 730,\n",
       " 'thin': 731,\n",
       " 'redhead': 732,\n",
       " 'gathered': 733,\n",
       " 'streak': 734,\n",
       " 'barely': 735,\n",
       " 'considerable': 736,\n",
       " 'baby': 737,\n",
       " 'braid': 738,\n",
       " 'rocker': 739,\n",
       " 'beaming': 740,\n",
       " 'sideways': 741,\n",
       " 'going': 742,\n",
       " 'afraid': 743,\n",
       " 'loop': 744,\n",
       " 'lips': 745,\n",
       " 'attention': 746,\n",
       " 'upwards': 747,\n",
       " 'upperlip': 748,\n",
       " 'smal': 749,\n",
       " 'they': 750,\n",
       " 'died': 751,\n",
       " 'wild': 752,\n",
       " 'spots': 753,\n",
       " 'dimply': 754,\n",
       " 'through': 755,\n",
       " 'eat': 756,\n",
       " 'bejewelled': 757,\n",
       " 'eating': 758,\n",
       " 'receiving': 759,\n",
       " 'she': 760,\n",
       " 'skin': 761,\n",
       " 'structure': 762,\n",
       " 'well': 763,\n",
       " 'grown': 764,\n",
       " 'actually': 765,\n",
       " 'goaty': 766,\n",
       " 'painted': 767,\n",
       " 'cheebones': 768,\n",
       " 'chinese': 769,\n",
       " 'most': 770,\n",
       " 'checckbones': 771,\n",
       " 'mysterious': 772,\n",
       " 'listening': 773,\n",
       " 'fully': 774,\n",
       " 'gear': 775,\n",
       " 'triangle': 776,\n",
       " 'covered': 777,\n",
       " 'anf': 778,\n",
       " 'lip': 779,\n",
       " 'fancy': 780,\n",
       " 'crazy': 781,\n",
       " 'stripe': 782,\n",
       " 'coloure': 783,\n",
       " 'person': 784,\n",
       " 'circular': 785,\n",
       " 'arms': 786,\n",
       " 'hairclip': 787,\n",
       " 'even': 788,\n",
       " 'nostrils': 789,\n",
       " 'sweaty': 790,\n",
       " 'chestnut': 791,\n",
       " 'behind': 792,\n",
       " 'edges': 793,\n",
       " 'bery': 794,\n",
       " 'denim': 795,\n",
       " 'prominent': 796,\n",
       " 'aviator': 797,\n",
       " 'crying': 798,\n",
       " 'fo': 799,\n",
       " 'sized': 800,\n",
       " 'sneer': 801,\n",
       " 'frown': 802,\n",
       " 'softly': 803,\n",
       " 'headband': 804,\n",
       " 'lungs': 805,\n",
       " 'hanging': 806,\n",
       " 'over': 807,\n",
       " 'conceal': 808,\n",
       " 'a': 809,\n",
       " 'asain': 810,\n",
       " 'tattoo': 811,\n",
       " 'fur': 812,\n",
       " 'both': 813,\n",
       " 'put': 814,\n",
       " 'green': 815,\n",
       " 'hait': 816,\n",
       " 'yellowed': 817,\n",
       " 'sculpted': 818,\n",
       " 'big': 819,\n",
       " 'chequered': 820,\n",
       " 'stocky': 821,\n",
       " 'heterochromia': 822,\n",
       " 'spikey': 823,\n",
       " 'don': 824,\n",
       " 'fake': 825,\n",
       " 'defines': 826,\n",
       " 'sneering': 827,\n",
       " 'him': 828,\n",
       " 'traditional': 829,\n",
       " 'necklace': 830,\n",
       " 'strong': 831,\n",
       " 'speaking': 832,\n",
       " 'scruffy': 833,\n",
       " 'bushu': 834,\n",
       " 'tunnel': 835,\n",
       " 'danger': 836,\n",
       " 'an': 837,\n",
       " 'chubby': 838,\n",
       " 'voloured': 839,\n",
       " 'visibl': 840,\n",
       " 'longish': 841,\n",
       " 'streaks': 842,\n",
       " 'accentuated': 843,\n",
       " 'comes': 844,\n",
       " 'asian': 845,\n",
       " 'shorter': 846,\n",
       " 'bulbous': 847,\n",
       " 'together': 848,\n",
       " 'bays': 849,\n",
       " 'forming': 850,\n",
       " 'hairy': 851,\n",
       " 'curved': 852,\n",
       " 'neck': 853,\n",
       " 'something': 854,\n",
       " 'also': 855,\n",
       " 'feint': 856,\n",
       " 'diamond': 857,\n",
       " 'pressing': 858,\n",
       " 'gelled': 859,\n",
       " 'heart': 860,\n",
       " 'crossed': 861,\n",
       " 'locked': 862,\n",
       " 'woma': 863,\n",
       " 'disbelief': 864,\n",
       " 'clock': 865,\n",
       " 'turning': 866,\n",
       " 'grinning': 867,\n",
       " 'above': 868,\n",
       " 'grey': 869,\n",
       " 'lighter': 870,\n",
       " 'tattooed': 871,\n",
       " 'shot': 872,\n",
       " 'orange': 873,\n",
       " 'centre': 874,\n",
       " 'style': 875,\n",
       " 'determined': 876,\n",
       " 'summery': 877,\n",
       " 'lipstick': 878,\n",
       " 'bandana': 879,\n",
       " 'lady': 880,\n",
       " 'emotionless': 881,\n",
       " 'highlights': 882,\n",
       " 'pinched': 883,\n",
       " 'mohawk': 884,\n",
       " 'this': 885,\n",
       " 'silky': 886,\n",
       " 'jewelled': 887,\n",
       " 'falls': 888,\n",
       " 'coloutred': 889,\n",
       " 'which': 890,\n",
       " 'cheek': 891,\n",
       " 'camera': 892,\n",
       " 'puffy': 893,\n",
       " 'glasses': 894,\n",
       " 'slim': 895,\n",
       " 'here': 896,\n",
       " 'japanese': 897,\n",
       " 'white': 898,\n",
       " 'edge': 899,\n",
       " 'seqend': 900,\n",
       " 'gap': 901,\n",
       " 'using': 902,\n",
       " 'partially': 903,\n",
       " 'bright': 904,\n",
       " 'thinly': 905,\n",
       " 'serious': 906,\n",
       " 'facial': 907,\n",
       " 'feminine': 908,\n",
       " 'teasing': 909,\n",
       " 'reddened': 910,\n",
       " 'to': 911,\n",
       " 'paisley': 912,\n",
       " 'grow': 913,\n",
       " 'frustrated': 914,\n",
       " 'eyebroes': 915,\n",
       " 'pearly': 916,\n",
       " 'strand': 917,\n",
       " 'staring': 918,\n",
       " 'darkish': 919,\n",
       " 'slanted': 920,\n",
       " 'lipsw': 921,\n",
       " 'started': 922,\n",
       " 'does': 923,\n",
       " 'medium': 924,\n",
       " 'placed': 925,\n",
       " 'winged': 926,\n",
       " 'being': 927,\n",
       " 'androgynous': 928,\n",
       " 'line': 929,\n",
       " 'closed': 930,\n",
       " 'gingerish': 931,\n",
       " 'pink': 932,\n",
       " 'pouty': 933,\n",
       " 'particularly': 934,\n",
       " 'breathing': 935,\n",
       " 'scared': 936,\n",
       " 'sunken': 937,\n",
       " 'guard': 938,\n",
       " 'squinting': 939,\n",
       " 'flawless': 940,\n",
       " 'clean': 941,\n",
       " 'seqstart': 942,\n",
       " 'where': 943,\n",
       " 'ones': 944,\n",
       " 'mask': 945,\n",
       " 'lashes': 946,\n",
       " 'makes': 947,\n",
       " 'sparse': 948,\n",
       " 'lops': 949,\n",
       " 'stressed': 950,\n",
       " 'glove': 951,\n",
       " 'thumbs': 952,\n",
       " 'turbans': 953,\n",
       " 'headwear': 954,\n",
       " 'have': 955,\n",
       " 'giggling': 956,\n",
       " 'caramel': 957,\n",
       " 'fair': 958,\n",
       " 'pearl': 959,\n",
       " 'ombre': 960,\n",
       " 'dull': 961,\n",
       " 'easily': 962,\n",
       " 'aorund': 963,\n",
       " 'shoer': 964,\n",
       " 'totally': 965,\n",
       " 'drawn': 966,\n",
       " 'pepper': 967,\n",
       " 'jaline': 968,\n",
       " 'upper': 969,\n",
       " 'as': 970,\n",
       " 'few': 971,\n",
       " 'sunburnt': 972,\n",
       " 'flat': 973,\n",
       " 'dainty': 974,\n",
       " 'ld': 975,\n",
       " 'pronounced': 976,\n",
       " 'tie': 977,\n",
       " 'focused': 978,\n",
       " 'cowboy': 979,\n",
       " 'outwards': 980,\n",
       " 'ecstatic': 981,\n",
       " 'sticker': 982,\n",
       " 'sweatr': 983,\n",
       " 'longer': 984,\n",
       " 'sticking': 985,\n",
       " 'horsetail': 986,\n",
       " 'same': 987,\n",
       " 'therefore': 988,\n",
       " 'noice': 989,\n",
       " 'surprised': 990,\n",
       " 'slick': 991,\n",
       " 'could': 992,\n",
       " 'goatee': 993,\n",
       " 'wears': 994,\n",
       " 'expression': 995,\n",
       " 'strange': 996,\n",
       " 'darkened': 997,\n",
       " 'doesn': 998,\n",
       " 'dace': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordtoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "maxv=0\n",
    "for i in f2t['description']:\n",
    "    maxv=max(maxv,len(i.split()))\n",
    "print(maxv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "model = Xception(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model_new = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import preprocess_input\n",
    "def preprocess(imag):\n",
    "    x = imag\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(image):\n",
    "    image = preprocess(image) # preprocess the image\n",
    "    fea_vec = model_new.predict(image) # Get the encoding vector for the image\n",
    "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape from (1, 2048) to (2048, )\n",
    "    return fea_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator, intended to be used in a call to model.fit_generator()\n",
    "def data_generator(descriptions, photos, wordtoix, max_length, num_photos_per_batch):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n=0\n",
    "    # loop for ever over images\n",
    "    while 1:\n",
    "        for i in range(len(descriptions)):\n",
    "            n+=1\n",
    "            # retrieve the photo feature\n",
    "            photo = photos[f2t['filename'][i]]\n",
    "            desc=descriptions[i]\n",
    "                # encode the sequence\n",
    "            seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
    "                # split one sequence into multiple X, y pairs\n",
    "            for i in range(1, len(seq)):\n",
    "                    # split into input and output pair\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                in_seq = pad_sequences([in_seq], maxlen=maxv)[0]\n",
    "                    # encode output sequence\n",
    "                out_seq = to_categorical([out_seq], num_classes=len(vocab))[0]\n",
    "                    # store\n",
    "                X1.append(photo)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "            # yield the batch data\n",
    "            if n==num_photos_per_batch:\n",
    "                yield [[array(X1), array(X2)], array(y)]\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE=os.path.join('glove.6B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE,encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecdim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(vocab), vecdim))\n",
    "\n",
    "for word, i in wordtoin.items():\n",
    "    embedding_vector=None\n",
    "    if(word in embeddings_index.keys()):\n",
    "        embedding_vector = embeddings_index[word]\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in the embedding index will be all zeros\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1336, 200)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "from pickle import dump, load\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
    "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.merge import add\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "from keras import optimizers\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "inputs1 = Input(shape=(2048,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "inputs2 = Input(shape=(maxv,))\n",
    "se1 = Embedding(len(vocab), vecdim, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(len(vocab), activation='softmax')(decoder2)\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "number_pics_per_bath = 3\n",
    "steps = len(f2t['description'])//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_x_19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedySearch(photo):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(maxv):\n",
    "        sequence = [wordtoin[w] for w in in_text.split() if w in wordtoin]\n",
    "        sequence = pad_sequences([sequence], maxlen=maxv)\n",
    "        yhat = model.predict([photo,sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = intoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == 'seqend':\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "shape_predictor = dlib.shape_predictor(r'shape_predictor_5_face_landmarks.dat')\n",
    "fa = face_utils.facealigner.FaceAligner(shape_predictor, desiredFaceWidth=299, desiredLeftEye=(0.4, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\__init__.py:89: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\handlers\\backend\\upsample.py:15: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:37: UserWarning: Unknown op ConstantFill in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of ConvInteger in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of DequantizeLinear in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of GatherND in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:37: UserWarning: Unknown op ImageScaler in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of IsInf in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of MatMulInteger in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of Mod in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of NonMaxSuppression in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of QLinearConv in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of QLinearMatMul in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of QuantizeLinear in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of Range in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of Resize in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of ReverseSequence in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of Round in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of ScatterElements in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of ScatterND in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\common\\handler_helper.py:34: UserWarning: Fail to get since_version of ThresholdedRelu in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\handlers\\backend\\reshape.py:31: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\onnx_tf\\handlers\\backend_handler.py:182: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "def area_of(left_top, right_bottom):\n",
    "    \"\"\"\n",
    "    Compute the areas of rectangles given two corners.\n",
    "    Args:\n",
    "        left_top (N, 2): left top corner.\n",
    "        right_bottom (N, 2): right bottom corner.\n",
    "    Returns:\n",
    "        area (N): return the area.\n",
    "    \"\"\"\n",
    "    hw = np.clip(right_bottom - left_top, 0.0, None)\n",
    "    return hw[..., 0] * hw[..., 1]\n",
    "\n",
    "def iou_of(boxes0, boxes1, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Return intersection-over-union (Jaccard index) of boxes.\n",
    "    Args:\n",
    "        boxes0 (N, 4): ground truth boxes.\n",
    "        boxes1 (N or 1, 4): predicted boxes.\n",
    "        eps: a small number to avoid 0 as denominator.\n",
    "    Returns:\n",
    "        iou (N): IoU values.\n",
    "    \"\"\"\n",
    "    overlap_left_top = np.maximum(boxes0[..., :2], boxes1[..., :2])\n",
    "    overlap_right_bottom = np.minimum(boxes0[..., 2:], boxes1[..., 2:])\n",
    "\n",
    "    overlap_area = area_of(overlap_left_top, overlap_right_bottom)\n",
    "    area0 = area_of(boxes0[..., :2], boxes0[..., 2:])\n",
    "    area1 = area_of(boxes1[..., :2], boxes1[..., 2:])\n",
    "    return overlap_area / (area0 + area1 - overlap_area + eps)\n",
    "\n",
    "def hard_nms(box_scores, iou_threshold, top_k=-1, candidate_size=200):\n",
    "    \"\"\"\n",
    "    Perform hard non-maximum-supression to filter out boxes with iou greater\n",
    "    than threshold\n",
    "    Args:\n",
    "        box_scores (N, 5): boxes in corner-form and probabilities.\n",
    "        iou_threshold: intersection over union threshold.\n",
    "        top_k: keep top_k results. If k <= 0, keep all the results.\n",
    "        candidate_size: only consider the candidates with the highest scores.\n",
    "    Returns:\n",
    "        picked: a list of indexes of the kept boxes\n",
    "    \"\"\"\n",
    "    scores = box_scores[:, -1]\n",
    "    boxes = box_scores[:, :-1]\n",
    "    picked = []\n",
    "    indexes = np.argsort(scores)\n",
    "    indexes = indexes[-candidate_size:]\n",
    "    while len(indexes) > 0:\n",
    "        current = indexes[-1]\n",
    "        picked.append(current)\n",
    "        if 0 < top_k == len(picked) or len(indexes) == 1:\n",
    "            break\n",
    "        current_box = boxes[current, :]\n",
    "        indexes = indexes[:-1]\n",
    "        rest_boxes = boxes[indexes, :]\n",
    "        iou = iou_of(\n",
    "            rest_boxes,\n",
    "            np.expand_dims(current_box, axis=0),\n",
    "        )\n",
    "        indexes = indexes[iou <= iou_threshold]\n",
    "\n",
    "    return box_scores[picked, :]\n",
    "\n",
    "def predict(width, height, confidences, boxes, prob_threshold, iou_threshold=0.5, top_k=-1):\n",
    "    \"\"\"\n",
    "    Select boxes that contain human faces\n",
    "    Args:\n",
    "        width: original image width\n",
    "        height: original image height\n",
    "        confidences (N, 2): confidence array\n",
    "        boxes (N, 4): boxes array in corner-form\n",
    "        iou_threshold: intersection over union threshold.\n",
    "        top_k: keep top_k results. If k <= 0, keep all the results.\n",
    "    Returns:\n",
    "        boxes (k, 4): an array of boxes kept\n",
    "        labels (k): an array of labels for each boxes kept\n",
    "        probs (k): an array of probabilities for each boxes being in corresponding labels\n",
    "    \"\"\"\n",
    "    boxes = boxes[0]\n",
    "    confidences = confidences[0]\n",
    "    picked_box_probs = []\n",
    "    picked_labels = []\n",
    "    for class_index in range(1, confidences.shape[1]):\n",
    "        probs = confidences[:, class_index]\n",
    "        mask = probs > prob_threshold\n",
    "        probs = probs[mask]\n",
    "        if probs.shape[0] == 0:\n",
    "            continue\n",
    "        subset_boxes = boxes[mask, :]\n",
    "        box_probs = np.concatenate([subset_boxes, probs.reshape(-1, 1)], axis=1)\n",
    "        box_probs = hard_nms(box_probs,\n",
    "           iou_threshold=iou_threshold,\n",
    "           top_k=top_k,\n",
    "           )\n",
    "        picked_box_probs.append(box_probs)\n",
    "        picked_labels.extend([class_index] * box_probs.shape[0])\n",
    "    if not picked_box_probs:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "    picked_box_probs = np.concatenate(picked_box_probs)\n",
    "    picked_box_probs[:, 0] *= width\n",
    "    picked_box_probs[:, 1] *= height\n",
    "    picked_box_probs[:, 2] *= width\n",
    "    picked_box_probs[:, 3] *= height\n",
    "    return picked_box_probs[:, :4].astype(np.int32), np.array(picked_labels), picked_box_probs[:, 4]\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "onnx_path = r'C:\\Users\\shrey\\Desktop\\Face2Text\\ultra_light_640.onnx'\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "predictor = prepare(onnx_model)\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "frame_count=0\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if frame is not None:\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # preprocess img acquired\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # convert bgr to rgb\n",
    "        img = cv2.resize(img, (640, 480)) # resize\n",
    "        img_mean = np.array([127, 127, 127])\n",
    "        img = (img - img_mean) / 128\n",
    "        img = np.transpose(img, [2, 0, 1])\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        confidences, boxes = ort_session.run(None, {input_name: img})\n",
    "        boxes, labels, probs = predict(w, h, confidences, boxes, 0.7)\n",
    "        areas={}\n",
    "        for i in range(boxes.shape[0]):\n",
    "            box = boxes[i, :]\n",
    "            x1, y1, x2, y2 = box\n",
    "            area=np.abs(x1-x2)*np.abs(y1-y2)\n",
    "            areas[(x1,y1,x2,y2)]=(area)\n",
    "        areas={k: v for k, v in sorted(areas.items(), key=lambda item: item[1],reverse=True)}\n",
    "        boxes = list(areas.keys())[:1]\n",
    "            \n",
    "        \n",
    "        colorList=[(0,0,255),(255,0,0),(0,0,255)]\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), colorList[i%3], 2)\n",
    "            #cv2.rectangle(frame, (x1, y2 - 20), (x2, y2), (80,18,236), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            \n",
    "            #x1, y1, x2, y2 = boxes[0,:]\n",
    "            # convert to gray scale image\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # align and resize\n",
    "            aligned_face = fa.align(frame, gray, dlib.rectangle(left = x1, top=y1, right=x2, bottom=y2))\n",
    "            aligned_face = cv2.resize(aligned_face, (299,299))  #299*299*3\n",
    "            \n",
    "            aligned_face = encode(aligned_face).reshape((1,2048))\n",
    "\n",
    "            desc = greedySearch(aligned_face)\n",
    "            #print(len(desc))\n",
    "            cv2.putText(frame, desc[:70], (0, (0+10)), font, 0.5, colorList[i%3], 1)\n",
    "            cv2.putText(frame, desc[70:140], (0, ( 10+ 15)), font, 0.5, colorList[i%3], 1)\n",
    "            cv2.putText(frame, desc[140:210], (0, ( 30+10)), font, 0.5, colorList[i%3], 1)\n",
    "            cv2.putText(frame, desc[210:280], (0, ( 45+10)), font, 0.5, colorList[i%3], 1)\n",
    "            cv2.putText(frame, desc[280:350], (0, (60+10)), font, 0.5, colorList[i%3], 1)\n",
    "            cv2.putText(frame, desc[350:420], (0, (75+10)), font, 0.5, colorList[i%3], 1)\n",
    "            cv2.putText(frame, desc[420:], (0, (90+10)), font, 0.5, colorList[i%3], 1)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "        #frame_count += 1\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
